{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB4iDFb79UHZ"
      },
      "source": [
        "Σημείωσεις: Η διαδικασία της εκπαίδευσης απο τον k-NN classifier ακόμα πήρε πολλές ώρες, σε σημείο που δεν είχα το κουράγιο να πατήσω ξανά το run (λες και έγω εκπαίδευα το μοντέλο :') ). Όπως και να έχει debug δεν έγινε λόγω του περιορισμένου χρόνου κυρίως οπότε είναι μάλλον αρκετά λάθος. Ελπίζω να μην σας βγουν τα μάτια.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pR95ok9pbDcU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAAXLaT61_5c"
      },
      "source": [
        "# 1. Εισαγωγή δεδομένων και προεργασία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ8RwmxvebjQ",
        "outputId": "35ea294f-c0d1-4215-8142-f5d4029ee134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Archive:  gdrive/MyDrive/ML Data/YearPredictionMSD_short.zip\n",
            "  inflating: YearPredictionMSD_short.csv  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!unzip gdrive/MyDrive/ML\\ Data/YearPredictionMSD_short.zip #gdrive/MyDrive/ΑρχείαΜαθημάτων/ΑρχείαΕργασιών/YearPredictionMSD.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxwxG-bpo8H4"
      },
      "outputs": [],
      "source": [
        "read_file = pd.read_csv('/content/YearPredictionMSD_short.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXxVF5chgNvg"
      },
      "source": [
        "##Απάντηση 1ου ερωτήματος"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "Rvw2HccmgK0V",
        "outputId": "0ad39615-fc16-47e1-89d1-9a44d04e03ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target variable values that are present in the data set are [1922 - 2010]\n",
            "[(2007, 3781), (2006, 3572), (2008, 3429), (2005, 3407), (2004, 3182), (2002, 2682), (2003, 2461), (2009, 2390), (2001, 2086), (1999, 2016), (2000, 2015), (1998, 1613), (1997, 1537), (1996, 1349), (1995, 1339), (1994, 1161), (1993, 1097), (1992, 940), (2010, 766), (1990, 751), (1991, 751), (1988, 622), (1987, 567), (1989, 567), (1986, 377), (1984, 324), (1985, 304), (1982, 303), (1973, 301), (1979, 295), (1975, 274), (1977, 274), (1980, 274), (1976, 261), (1981, 259), (1983, 243), (1974, 234), (1972, 231), (1970, 225), (1978, 193), (1971, 190), (1969, 172), (1964, 154), (1967, 131), (1968, 116), (1965, 100), (1966, 99), (1963, 90), (1961, 84), (1959, 63), (1956, 52), (1962, 46), (1958, 40), (1957, 39), (1960, 37), (1955, 25), (1954, 19), (1952, 14), (1935, 8), (1937, 8), (1949, 8), (1926, 6), (1945, 6), (1928, 5), (1941, 5), (1948, 5), (1950, 5), (1951, 5), (1922, 4), (1932, 4), (1936, 4), (1938, 4), (1942, 4), (1946, 4), (1953, 4), (1927, 3), (1930, 3), (1933, 1)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "list1 = read_file.iloc[:, 0].tolist()\n",
        "\n",
        "def minmax(alist, flag):\n",
        "    min_value = min(alist)\n",
        "    max_value = max(alist)\n",
        "\n",
        "    if flag:\n",
        "        print(f\"The target variable values that are present in the data set are [{min_value} - {max_value}]\")\n",
        "    else: \n",
        "        print(f\"The independent variable values that are present in the data set are [{min_value} - {max_value}]\")\n",
        "\n",
        "minmax(list1, 1)\n",
        "\n",
        "\n",
        "#Not a pythonista.... yet, did it the old, plain, boring (in all capital)manly way not in the sugarboy python one.\n",
        "def counterElem(alist):\n",
        "\n",
        "    locDic = {}\n",
        "    for j in alist:\n",
        "        if j in locDic:\n",
        "            locDic[j] += 1\n",
        "        else:\n",
        "            locDic[j] = 1\n",
        "\n",
        "    return locDic\n",
        "\n",
        "\n",
        "print(sorted(counterElem(list1).items(),key = lambda x:x[1], reverse = True))\n",
        "\n",
        "plt.figure(figsize = (10, 10))\n",
        "plt.hist(list1, bins = 88)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJd8OuuXYt9C",
        "outputId": "7bbb58b6-8437-471e-c8c7-0a822a803bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The independent variable values that are present in the data set are [-0.36909 - 87.42967]\n"
          ]
        }
      ],
      "source": [
        "list2 = read_file.iloc[:, 1:]\n",
        "\n",
        "minmax(list2, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52wEZR84oYO7"
      },
      "source": [
        "Το φάσμα τιμών απο όσο φαίνεται παραπάνω είναι αρκετά μεγάλο για να δικαιολογήσει την χρήση scalling. Γενικότερα όπως έχουμε δει δεν είναι (σχεδόν) ποτέ κακό να εφαρμόζει κανείς scalling, πόσο μάλλον όπως στην προκειμένη εφαρμογή που ένας απο τους αλγορίθμους που θα χρειαστούμε (k-NN) είναι αρκετά ευαίσθητος στα διάφορα μεγέθοι.\n",
        "\n",
        "Το πρόβλημα πιστευώ θα ήταν καλύτερο να αντιμετωπιστεί ως ένα της ταξινόμησης καθώς θέλουμε απο το μοντέλο μας να προβλέψει διακριτές τιμές-κλάσεις που είναι οι χρονίες. Δεν θεωρώ οτι θα ήταν σωστή η προσέγγιση της χρονίας σαν μια συνεχή τιμή.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVQlwUns2TUx"
      },
      "source": [
        "# 2. Συνάρτηση αξιολόγησης"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8h3_Fn1d2Xjm"
      },
      "outputs": [],
      "source": [
        "def evalMeasurment(ground_truth, predictions, N):\n",
        "\n",
        "    percentage = 0.0\n",
        "    counter = 0\n",
        "    for i in predictions:\n",
        "        if i - ground_truth[i] <= N:\n",
        "            counter += 1 \n",
        "\n",
        "    percentage = counter/len(predictions)\n",
        "    return percentage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iqaAQehZI6k"
      },
      "source": [
        "##Διαχωρισμός Test-Train και Standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl_Un-A5ZFSM",
        "outputId": "69d646f6-a6c2-4d5a-c5ba-74b583c0d710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50020, 90)\n",
            "(50020,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "\n",
        "X = read_file.iloc[:, 1:]\n",
        "y = read_file.iloc[:, 0]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 40000)\n",
        "\n",
        "\n",
        "#lab = preprocessing.LabelEncoder()\n",
        "#y_train = lab.fit_transform(y)\n",
        "\n",
        "\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGItugmx7dP1"
      },
      "source": [
        "# 3. Ταξινόμηση"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85TIgQ-FxzF4"
      },
      "source": [
        "##k-Nearest Neighbors classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oCUMOZSQ7fYj",
        "outputId": "31647541-8804-4803-8339-03c95a89c224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=uniform;, score=0.200 total time=   5.4s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=uniform;, score=0.208 total time=   5.0s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=uniform;, score=0.195 total time=   4.9s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=1, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=uniform;, score=0.158 total time=   5.5s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=uniform;, score=0.160 total time=   5.6s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=uniform;, score=0.158 total time=   5.5s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=2, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=uniform;, score=0.145 total time=   6.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=uniform;, score=0.150 total time=   6.2s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=uniform;, score=0.148 total time=   6.2s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=weighted;, score=nan total time=   0.0s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=weighted;, score=nan total time=   0.0s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=3, kNNClassifier__weights=weighted;, score=nan total time=   0.0s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=uniform;, score=0.142 total time=   9.0s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=uniform;, score=0.148 total time=   8.7s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=uniform;, score=0.144 total time=   8.7s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=4, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=uniform;, score=0.144 total time=   9.0s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=uniform;, score=0.147 total time=   8.6s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=uniform;, score=0.145 total time=   8.7s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=5, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=uniform;, score=0.147 total time=   9.0s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=uniform;, score=0.148 total time=   8.6s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=uniform;, score=0.145 total time=   8.8s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=6, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=uniform;, score=0.147 total time=  10.1s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=uniform;, score=0.150 total time=   8.6s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=uniform;, score=0.145 total time=   8.7s\n",
            "[CV 1/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=weighted;, score=nan total time=   0.0s\n",
            "[CV 2/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=weighted;, score=nan total time=   0.0s\n",
            "[CV 3/3] END kNNClassifier__n_neighbors=7, kNNClassifier__weights=weighted;, score=nan total time=   0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "21 fits failed out of a total of 42.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "21 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_classification.py\", line 196, in fit\n",
            "    self.weights = _check_weights(self.weights)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py\", line 83, in _check_weights\n",
            "    \"weights not recognized: should be 'uniform', \"\n",
            "ValueError: weights not recognized: should be 'uniform', 'distance', or a callable function\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.20075003        nan 0.15890002        nan 0.14760006        nan\n",
            " 0.14460005        nan 0.14505003        nan 0.14637499        nan\n",
            " 0.14720001        nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Αποτελέσματα k-nearest neighbors classification:\n**Best k**: 1.000<br>**Best weighting**: uniform<br>**Best Cross-Val Accuracy**: 0.20<br>**Test Set Accuracy**: 0.25<br>**Test Set F1**: 0.25<br>**Test Set Self Measurment for N = 3**: 0.05<br>**Test Set Self Measurment for N = 5**: 0.07<br>**Confusion matrix**:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "   0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    1    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    7    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    1    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    1    0    0    0    0    1    1    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    1    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0    1    1    0    1    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    1    0    0    0    0    0    0    0    0    2    0    0    0    0    1    0    0    1    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    7    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    0    0    0    0    0    3    0    1    1    1    1    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    1    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    1    0    0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    6    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    0    0    0    1    0    1    1    1    1    0    0    0    0    0    2    0    2    0    1    2    0    1    0    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1   12    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    0    0    1    0    1    0    0    0    1    0    0    1    1    0    0    0    0    2    0    1    0    0    0    0    1    1    2    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    7    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    1    1    1    1    0    1    0    0    0    0    1    0    1    2    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    0    2    2    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    3    1    0    0    0    0    2    0    0    1    0    0    0    0    0    1    0    1    2    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    2    0    0    4    2    1    1    1    0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    1    0    0    0    0    1    1    0    0    0    0    0    0    0    1    2    1    0    1    0    1    2    0    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    1    0    0    1    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    1    1    0    0    1    0    0    2    0    0    0    2    0    0    2    2    0    1    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    1    0    0    0    9    2    0    0    0    0    1    0    0    1    0    1    0    0    0    0    0    0    1    0    0    1    0    1    0    1    0    0    0    0    0    1    0    1    1    1    2    3    2    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    1    1    1   18    1    2    0    0    1    0    1    1    0    1    0    0    1    1    0    0    0    1    0    2    1    0    1    2    0    2    0    0    1    1    1    0    0    1    1    4    1    2    0    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    8    3    1    1    0    0    0    0    0    1    0    0    0    0    0    1    1    0    0    0    0    1    0    1    1    0    0    2    1    0    1    4    1    1    2    3    2    0    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    0    1    1    1   16    2    0    0    0    0    1    0    0    0    1    0    0    1    0    1    1    1    0    0    1    1    0    2    1    3    2    2    0    1    0    0    4    0    1    3    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    2    0    0   13    2    0    2    0    2    0    1    1    1    0    0    1    1    0    1    0    0    1    1    3    2    1    1    2    1    0    0    1    0    2    1    1    1    3    3    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1   11    0    4    1    0    0    0    0    0    1    1    1    0    0    1    0    0    0    0    0    1    3    1    3    1    1    0    1    3    1    2    2    3    0    3    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1   10    2    3    1    0    1    2    0    0    0    1    2    0    2    0    0    0    1    1    1    2    0    1    2    3    5    0    0    4    1    4    4    1    1    0    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    1    0    1   14    1    0    1    0    1    2    1    0    0    0    0    0    0    0    0    1    0    1    3    1    2    3    2    1    0    0    1    1    1    3    1    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    2    1    0    0   16    2    0    0    0    0    0    1    0    2    1    0    0    1    3    0    2    0    1    2    0    2    2    4    1    3    2    0    1    2    1    5    1    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    1    0    1    3    7    0    0    1    0    0    1    0    2    0    3    0    0    2    1    2    2    0    2    2    1    0    0    1    1    1    2    3    2    1    2    1    0\n",
            "   0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1   11    2    1    0    0    1    0    1    1    0    4    0    0    2    1    1    1    1    1    0    1    1    2    3    3    3    1    9    1    3    0    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    2    0    2   13    1    0    2    2    0    1    0    1    0    1    0    1    0    0    3    1    0    3    0    1    0    3    1    1    2    2    1    1    2    2\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    2    0    0    2   13    1    2    0    0    0    0    0    0    1    1    3    0    1    2    0    0    0    1    0    3    2    1    1    2    4    1    1    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    1    1    0    1    0    3    1    0    0    1   12    3    0    0    1    1    0    1    1    2    1    3    1    4    0    0    0    1    1    1    3    2    2    3    6    0    2    1    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0   11    1    1    1    1    2    0    1    0    4    1    0    1    1    0    1    2    2    0    2    2    1    1    4    0    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    2    0    1    2   15    2    0    2    2    0    4    2    2    0    1    4    0    1    3    2    2    2    2    1    2    3    3    1    6    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    0    0    1    1    1    1    1    0    0    1   12    3    1    1    1    1    0    1    0    2    2    0    3    3    3    2    2    2    1    3    1    2    1    1    2    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    1    0    0    1    1    0    0    0    1    0    0    1   24    3    8    2    1    1    2    5    1    0    3    1    0    2    4    2    4    0    1    2    1    1    3    1    2\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    1    1    0    1    0    0    0    0    0    4    3   46    4    2    5    1    2    1    2    2    2    2    1    5    4    4    4    2    5    1    2    7    4    3    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    1    0    0    1    0    0    1    1    1    0    0    0    0    0    0    1    2   33    2    4    2    6    1    5    6    0    2    4    1    0    1    4    1    0    7    2    4    1    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0    1    0    0    0    0    0    0    1    1    0    0    1    0    1    2    5   31    5    3    9    2    5    0    1    3    2    6    2    4    5    3    1    2    3    4    1    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    1    0    1    0    0    0    0    0    1    2    1    1    0    2    0    1    1    0    1    0    2    2    1    1    2    4   41    7    2    6    1    7    2    2    2    5    3    6    5    1    6    4    6    3    4    4    0\n",
            "   0    0    0    0    0    0    1    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    2    3    1    1    0    1    0    0    0    1    1    2    1    1    5    3    3    4   44    5    5    3    5    5    2    5    4    2    4    4    3    6    9    1    3    7    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    1    1    0    0    2    3    1    0    0    0    0    2    2    0    3    2    6    1    6   60    2    6    5    5    2    5    2    2   10    3    6    5   10    2    9   11    6    2\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    0    0    2    1    1    0    0    0    2    2    2    3    2    0    1    0    0    0    1    3    1    4    4    3    1    2    4    2   71    6    7    3    9   10    6    6    5    4    4   11    9    6   10    9    3    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    1    0    0    0    0    1    1    0    0    2    1    1    0    1    1    0    1    1    0    1    3    1    0    5    5    1    5    5   11    7   54    7    8    4    6   10    5    7   11    8   11   13    6   12    6    4    2\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    2    1    0    1    2    2    1    1    2    0    2    0    1    1    1    3    0    2    2    5    2    7    1    8    6    7   52   10   11   14   12    6   14   11    4   17    8   15    8    6    4    4\n",
            "   0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0    1    1    0    3    0    0    1    1    1    0    2    1    1    1    0    1    2    3    1    2    3    7    3    5    7    6    9   78   15    5    6   10   11   11   11   19    9    6    9    4    7    3\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0    0    0    0    1    2    1    0    1    4    1    2    1    0    0    0    2    0    1    5    3    4    2    6    4    9    8   10   10   74    8   18    9   11   23   14   10   18   14   13   16    9    1\n",
            "   0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    1    1    0    3    3    1    0    1    3    0    3    1    0    2    3    3    4    3    1    1    4    2    6    6    7    9    8   85   14   10   12   15   12   20   20   16   11   18    8    2\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    1    0    1    0    1    0    3    1    2    0    2    2    0    3    0    3    2    2    2    2    0    3    8    3    8    8    6   13    9    9   10   16   17   85   13   17   17   13   20   19   17   15   21   14    5\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    3    1    6    0    1    2    2    2    1    6    0    0    0    2    0    1    1    4    0    3    4   11   11    7    9   15   15   12   20   86   22   21   16   20   13   23   21   17   14    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    1    0    0    1    1    0    0    2    0    1    1    1    2    3    2    2    2    0    1    3    3    2    3    0    1    5    3    5    6    2    9    4    7   12   15   14   10   16   19   92   17   20   23   25   23   17   20    9    8\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    1    1    0    0    2    4    0    2    2    3    1    4    2    1    0    2    2    3    1    1    3    3    4    7    3    5    6   11    8    8   11   15   11   25   24   23  118   29   36   34   31   25   27   20    4\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    2    0    2    0    1    1    4    0    1    4    1    2    2    4    2    2    3    1    1    3    2    8    3    5    6    5    7   10    8   15   16   11   12   15   27   26  105   35   36   31   41   29   20    5\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    0    0    0    1    0    0    1    0    1    2    0    2    0    5    0    0    3    3    2    0    2    2    3    0    2    2    2    6    9    2    4    8    8   14    9   21   19   19   22   17   26   24   35   42  164   42   42   38   37   26   10\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    2    0    1    1    0    1    0    0    1    0    1    1    0    2    1    4    0    5    7    1    4    1    2    3    2    2    2    1    6    4    4    5   13    7    7   12   12   15   20   22   18   26   33   38   27   27  155   62   43   41   25    9\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    1    0    0    1    0    1    2    2    4    2    2    4    2    1    1    5    1    0    1    0    4    2    4    3    4    4    7    5   10   18    8   18   13   13   22   22   23   18   36   32   31   36  198   56   49   29   10\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    0    0    0    2    4    1    3    1    2    1    3    2    2    1    3    0    2    4    2    4    3    6    3    9    8    9   12    7   12   13   25   19   27   21   30   35   28   44   44   50  182   56   42   10\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    2    4    2    2    0    0    2    1    4    1    1    5    2    1    4    2    1    1    3    2    1    3    5    3    2    3    6    3    4    6    8   14   12   16   18   12   17   19   31   26   24   25   38   45   44   54  205   40   12\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    1    1    3    0    2    3    4    1    1    1    3    1    0    0    1    1    1    1    4    2    5    4    2    2    1    5   13    4   12    4    9   13   12   12   15   23   17   23   33   29   44   28  106    5\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    0    3    1    0    2    1    0    0    0    1    0    0    1    1    1    0    0    2    0    2    2    3    0    5    4    2    4    5    4    7    9    3   11    7    8   11    9   11   28\n"
          ]
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "knn_pipeline = Pipeline([('Scaler',  StandardScaler()),\n",
        "            ('kNNClassifier', KNeighborsClassifier())])\n",
        "\n",
        "\n",
        "params = {\n",
        "            'kNNClassifier__n_neighbors':   range(1,8),\n",
        "            'kNNClassifier__weights':   ['uniform', 'weighted']\n",
        "        }\n",
        "\n",
        "grid = GridSearchCV(estimator=knn_pipeline, cv = 3, param_grid=params, verbose=3)\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "y_train_pred = grid.predict(X_train)\n",
        "y_test_pred = grid.predict(X_test)\n",
        "\n",
        "\n",
        "display(Markdown(\n",
        "    \"### Αποτελέσματα k-nearest neighbors classification:\\n\" +\n",
        "    \"**Best k**: {:.3f}\".format(grid.best_params_['kNNClassifier__n_neighbors'])  + \"<br>\" +\n",
        "    \"**Best weighting**: {}\".format(grid.best_params_['kNNClassifier__weights'])  + \"<br>\" +\n",
        "    \"**Best Cross-Val Accuracy**: {:.2f}\".format(grid.best_score_) + \"<br>\" +\n",
        "    \"**Test Set Accuracy**: {:.2f}\".format(accuracy_score(y_test, y_test_pred)) + \"<br>\" +\n",
        "    \"**Test Set F1**: {:.2f}\".format(f1_score(y_test, y_test_pred,average='micro')) + \"<br>\" +\n",
        "    \"**Test Set Self Measurment for N = 3**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 3)) + \"<br>\" +\n",
        "     \"**Test Set Self Measurment for N = 5**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 5)) + \"<br>\" +\n",
        "    \"**Confusion matrix**:\"\n",
        "))\n",
        "\n",
        "\n",
        "print(\"\\n\".join([' '.join(['{:4}'.format(item) for item in row]) \n",
        "      for row in confusion_matrix(y_test,y_test_pred)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9AFfZ07x7S9"
      },
      "source": [
        "##Extremely Randomized Trees classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRciPxJ9yB1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "10b5e78a-fa47-4445-ffcb-433b1d095d33"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Αποτελέσματα Randomized Tree classification:\n**Training Set F1**: 1.00<br>**Test Set F1**: 0.17<br>**Test Set Self Measurment for N = 3**: 0.01<br>**Test Set Self Measurment for N = 5**: 0.01<br>**Confusion matrix**:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
            "   0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    0    0    0    1    0    0\n",
            "   0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    0    0    0    0    0    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    1    1    1    1    0    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    0    1    2    0    0    0    0    0    2    0    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    0    0    2    1    1    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    0    1    0    0    0    1    0    1    2    2    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    1    2    0    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    1    0    1    0    0    0    0    2    2    1    1    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    1    0    1    1    1    0    3    2    1    2    2    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    1    0    3    1    0    0    1    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    1    1    1    0    0    2    1    0    2    1    2    0    4    3    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    6    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    2    2    0    1    0    0    0    0    2    0    4    3    2    3    2    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    1    0    0    0    0    0    0    3    0    2    6    2    1    0    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    1    0    0    0    1    0    1    0    0    2    2    0    0    3    2    5    3    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    3    1    0    0    0    0    0    1    3    0    4    5    0    1    3    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    2    1    3    3    5    0    3    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    1    0    1    0    0    0    1    1    0    3    1    2    3    0    6    2    3    1    1    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    8    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    4    0    2    2    1    3    0    6    2    3    3   10    1    6    1    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    2    0    0    1    1    3   10    4    7    3    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    2    3    2    1    1    0    4    3    0    2    4    6    4    6    2    4    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    7    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    3    0    0    0    0    2    1    4    3    8    6    7    6    4    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    1    2    1    2    0    0    5    1    9    6    7    5    2    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    1    0    0    0    0    0    0    1    0    1    0    1    1    2    0    1    1    4    5    1    4    3    8    3   12    6    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    5    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    2    1    2    0    3    0    3    3    6    5    5    5    2    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    8    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    1    0    0    0    1    0    1    3    4    5   10    8    7    6    4    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    4    1    1    2    1    1    2    1    1    0    3    3    3    6    4    5    5    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4    0    0    0    0    0    0    0    1    0    0    0    0    3    0    0    3    1    0    1    2    2    1    5    2    6    6   10    4    7    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    5    0    0    0    0    0    0    0    0    0    0    0    0    1    1    1    0    3    1    0    3    1    3    2    5    6    5    5    8    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    7    0    0    0    0    0    0    0    1    0    0    1    0    2    1    0    0    1    1    0    1    3    0    4    6    8    5    5    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    1    0    1    0    1    0    2    0    1    2    1    0    1    3    4    6    2    5    7    4   10    5    4    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    3    0    1    0    0    1    0    0    0    1    1    4    1    1    0    1    2    0    2    3    3    3    7    3    3    1    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    3    0    1    0    0    0    2    1    0    3    1    2    0    2    2    3    1    2    7    1    3    7    5   12    8    3    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    5    0    1    0    0    0    1    1    0    0    2    1    1    1    3    0    1    4    1    5    8   10    6    5    4    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    9    1    2    0    0    3    0    1    0    5    0    0    3    1    1    2    5    2    8   11   10   12    4    1    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0   18    1    0    1    1    2    0    0    4    0    2    3    7    2    4    4    4   12   16   12   19    4    6    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    2    2   15    3    2    2    2    3    1    1    0    1    2    3    1    2    2    1   13   13   10    7   10    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0   19    0    2    4    2    2    0    0    2    6    0    2    6    7    2    7   19    8   10    6    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    0   25    0    3    2    3    4    5    1    7    6    0    7   10    5    9   18   12   12   11    0    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    2    0    1    2   22    0    2    3    2    4    5    3    7    3    7    9    4   18   10   13   21   10    3    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    1    0    0    1    2   30    3    5    9    3    3    3    6    5    6    8    5   18   20   19   22    9    6    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    1    1    1    0    0    5   38    0    5    3    3    3    6    2    6    8   10   26   18   29   32   19    4    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    2    5   28    5    5    6    1   10    3   10   16   11   23   27   28   31   14    3    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0    0    0    0    0    0    0    0    1    2    1    0    1    2    3    4   26    3    5    9   12    8   12   16   10   28   33   25   37   14    4    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    2    1    0    2    3    2   35    4    2    5    9    8   18   12   29   38   31   38   21    6    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    5    0    2    0    3    3   31    9   14    6    8   23   14   29   38   50   47   26    8    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    1    1    2    5   10    0    1   44    7    7   12   35   13   26   41   31   49   29    7    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    0    0    1    0    0    0    1    1    1    2    1    1    3    2    5    5    2   53   13    6   18   15   45   55   57   61   38    8    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    2    2    4    7    3    3    3   14   51   13   34   20   39   47   51   56   34    7    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    3    5    4    3    2    3   10    6   51   20   12   50   65   70   69   39    2    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    2    1    1    2    3    7    9   16   13   89   23   56   82   72   87   53    8    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    1    0    1    1    6    2    2    9    5    6   34   69   46   93   81   90   55   12    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2    0    2    1    1    5    2    6    8    8   16   14   45   33  128   93  114  124   65   13    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    2    4    2    4    5    5    7   17   13   11   51   30   57  154   92  136   67   17    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    3    1    1    3    7    1    5   10    8    8   13   41   33   57   95  201  138   73    9    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    2    1    5    4    7    6    6   16   31   18   79   98  120  234   88   16    1\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    1    0    0    0    4    0    3    3    2    2    3   11    5   12   32   22   64  112  106  164  172   18    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    0    0    0    0    2    0    1    3    6    4    6   24   15   40   62   72  105   58   54    0\n",
            "   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    0    1    0    0    0    0    1    1    2   10    4   23   17   25   28   27    5    5\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "Extra_clf = ExtraTreesClassifier()\n",
        "\n",
        "Extra_clf.fit(X_train, y_train)\n",
        "y_train_pred = Extra_clf.predict(X_train)\n",
        "y_test_pred = Extra_clf.predict(X_test)\n",
        "\n",
        "\n",
        "display(Markdown(\n",
        "    \"### Αποτελέσματα Randomized Tree classification:\\n\" +\n",
        "    \"**Training Set F1**: {:.2f}\".format(f1_score(y_train, y_train_pred, average='micro')) + \"<br>\" +\n",
        "    \"**Test Set F1**: {:.2f}\".format(f1_score(y_test, y_test_pred,average='micro')) + \"<br>\" +\n",
        "    \"**Test Set Self Measurment for N = 3**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 3)) + \"<br>\" +\n",
        "     \"**Test Set Self Measurment for N = 5**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 5)) + \"<br>\" +\n",
        "    \"**Confusion matrix**:\"\n",
        "))\n",
        "\n",
        "print(\"\\n\".join([' '.join(['{:4}'.format(item) for item in row]) \n",
        "      for row in confusion_matrix(y_test,y_test_pred)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO1rRSqr0p8p"
      },
      "source": [
        "#4. Παλινδρόμηση"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHLCD6Au7PVx"
      },
      "source": [
        "##k-Nearest Neighbors Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9LfAh2r0uqA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "29af3737-e6c2-4158-8ef0-838cd31d7bb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 14 candidates, totalling 42 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-da3f8f099c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    246\u001b[0m                     \u001b[0;34m\"Invalid parameter %s for estimator %s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;34m\"Check the list of available parameters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0;34m\"with `estimator.get_params().keys()`.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 )\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid parameter kNNRegressor for estimator Pipeline(steps=[('Scaler', StandardScaler()),\n                ('kNNClassifier', KNeighborsClassifier())]). Check the list of available parameters with `estimator.get_params().keys()`."
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "knnReg = KNeighborsRegressor()\n",
        "\n",
        "params = {\n",
        "            'kNNRegressor__n_neighbors':   range(1,8),\n",
        "            'kNNRegressor__weights':   ['uniform', 'weighted']\n",
        "        }\n",
        "\n",
        "grid = GridSearchCV(estimator=knn_pipeline, cv = 3, param_grid=params, verbose=3)\n",
        "\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "y_train_pred = grid.predict(X_train)\n",
        "y_test_pred = grid.predict(X_test)\n",
        "\n",
        "display(Markdown(\n",
        "    \"### Αποτελέσματα k-NN Regressor:\\n\" +\n",
        "    \"**Best k**: {:.3f}\".format(grid.best_params_['kNNRegressor__n_neighbors'])  + \"<br>\" +\n",
        "    \"**Best weighting**: {}\".format(grid.best_params_['kNNRegressor__weights'])  + \"<br>\" +\n",
        "    \"**Best Cross-Val Accuracy**: {:.2f}\".format(grid.best_score_) + \"<br>\" +\n",
        "    \"**Test Set R2**: {:.2f}\".format(r2_score(y_test, y_test_pred)) + \"<br>\" +\n",
        "    \"**Test Set Self Measurment for N = 3**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 3)) + \"<br>\" +\n",
        "     \"**Test Set Self Measurment for N = 5**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 5)) + \"<br>\" \n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fqxole6BGM2"
      },
      "source": [
        "##Extremely Randomized Trees regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlWOBCOqBFkl"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "Extra_regr = ExtraTreesRegressor()\n",
        "\n",
        "Extra_regr.fit(X_train, y_train)\n",
        "y_train_pred = Extra_regr.predict(X_train)\n",
        "y_test_pred = Extra_regr.predict(X_test)\n",
        "\n",
        "\n",
        "display(Markdown(\n",
        "    \"### Αποτελέσματα Randomized Tree regression:\\n\" +\n",
        "    \"**Training Set R2**: {:.2f}\".format(r2_score(y_train, y_train_pred)) + \"<br>\" +\n",
        "    \"**Test Set R2**: {:.2f}\".format(r2_score(y_test, y_test_pred)) + \"<br>\" +\n",
        "    \"**Test Set Self Measurment for N = 3**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 3)) + \"<br>\" +\n",
        "     \"**Test Set Self Measurment for N = 5**: {:.2f}\".format(evalMeasurment(y, y_test_pred, 5)) + \"<br>\" +\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1abk9YT74iP"
      },
      "source": [
        "#5. SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU3mnI567-GO"
      },
      "source": [
        "Γενικότερα η εκπαίδευση του SVM είνα μια απαιτητική διαδικασία. Η ιδανική του χρήση είναι για \"μικρά\" η \"μεσσαία\" προβλήματα. Σε ένα μεγάλο dataset όπως το συγκεκριμένο ίσως έκανε την διαδικασία εκπαίδευσης ασύμφορη."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7RBT2up9Hko"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}